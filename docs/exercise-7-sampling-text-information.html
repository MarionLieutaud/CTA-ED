<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 23 Exercise 7: Sampling text information | Computational Text Analysis</title>
<meta name="author" content="Christopher Barrie">
<meta name="description" content="23.1 Introduction The hands-on exercise for this week focuses on how to collect and/or sample text information. In this tutorial, you will learn how to: Access text information from online corpora...">
<meta name="generator" content="bookdown 0.31.1 with bs4_book()">
<meta property="og:title" content="Chapter 23 Exercise 7: Sampling text information | Computational Text Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://cjbarrie.github.io/CTA-ED/exercise-7-sampling-text-information.html">
<meta property="og:image" content="https://cjbarrie.github.io/CTA-ED/coverb.png">
<meta property="og:description" content="23.1 Introduction The hands-on exercise for this week focuses on how to collect and/or sample text information. In this tutorial, you will learn how to: Access text information from online corpora...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 23 Exercise 7: Sampling text information | Computational Text Analysis">
<meta name="twitter:description" content="23.1 Introduction The hands-on exercise for this week focuses on how to collect and/or sample text information. In this tutorial, you will learn how to: Access text information from online corpora...">
<meta name="twitter:image" content="https://cjbarrie.github.io/CTA-ED/coverb.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2.9000/transition.js"></script><script src="libs/bs3compat-0.4.2.9000/tabs.js"></script><script src="libs/bs3compat-0.4.2.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Computational Text Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">“Computational Text Analysis” (PGSP11584)</a></li>
<li><a class="" href="course-overview.html">Course Overview</a></li>
<li><a class="" href="introduction-to-r.html">Introduction to R</a></li>
<li><a class="" href="week-1.html"><span class="header-section-number">1</span> Week 1</a></li>
<li><a class="" href="week-2.html"><span class="header-section-number">2</span> Week 2</a></li>
<li><a class="" href="week-2-demo.html"><span class="header-section-number">3</span> Week 2 Demo</a></li>
<li><a class="" href="week-3.html"><span class="header-section-number">4</span> Week 3</a></li>
<li><a class="" href="week-3-demo.html"><span class="header-section-number">5</span> Week 3 Demo</a></li>
<li><a class="" href="week-4.html"><span class="header-section-number">6</span> Week 4</a></li>
<li><a class="" href="week-4-demo.html"><span class="header-section-number">7</span> Week 4 Demo</a></li>
<li><a class="" href="week-5.html"><span class="header-section-number">8</span> Week 5</a></li>
<li><a class="" href="week-5-demo.html"><span class="header-section-number">9</span> Week 5 Demo</a></li>
<li><a class="" href="week-6.html"><span class="header-section-number">10</span> Week 6</a></li>
<li><a class="" href="week-6-demo.html"><span class="header-section-number">11</span> Week 6 Demo</a></li>
<li><a class="" href="week-7.html"><span class="header-section-number">12</span> Week 7</a></li>
<li><a class="" href="week-7-demo.html"><span class="header-section-number">13</span> Week 7 Demo</a></li>
<li><a class="" href="week-8.html"><span class="header-section-number">14</span> Week 8</a></li>
<li><a class="" href="week-9.html"><span class="header-section-number">15</span> Week 9</a></li>
<li><a class="" href="week-10.html"><span class="header-section-number">16</span> Week 10</a></li>
<li><a class="" href="exercise-1-word-frequency-analysis.html"><span class="header-section-number">17</span> Exercise 1: Word frequency analysis</a></li>
<li><a class="" href="exercise-2-dictionary-based-methods.html"><span class="header-section-number">18</span> Exercise 2: Dictionary-based methods</a></li>
<li><a class="" href="exercise-3-comparison-and-complexity.html"><span class="header-section-number">19</span> Exercise 3: Comparison and complexity</a></li>
<li><a class="" href="exercise-4-scaling-techniques.html"><span class="header-section-number">20</span> Exercise 4: Scaling techniques</a></li>
<li><a class="" href="exercise-5-unsupervised-learning-topic-models.html"><span class="header-section-number">21</span> Exercise 5: Unsupervised learning (topic models)</a></li>
<li><a class="" href="exercise-6-unsupervised-learning-word-embedding.html"><span class="header-section-number">22</span> Exercise 6: Unsupervised learning (word embedding)</a></li>
<li><a class="active" href="exercise-7-sampling-text-information.html"><span class="header-section-number">23</span> Exercise 7: Sampling text information</a></li>
<li><a class="" href="exercise-9-validation.html"><span class="header-section-number">24</span> Exercise 9: Validation</a></li>
<li><a class="" href="assessment-data.html"><span class="header-section-number">25</span> Assessment data</a></li>
<li><a class="" href="references-2.html"><span class="header-section-number">26</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/cjbarrie/CTA-ED">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="exercise-7-sampling-text-information" class="section level1" number="23">
<h1>
<span class="header-section-number">23</span> Exercise 7: Sampling text information<a class="anchor" aria-label="anchor" href="#exercise-7-sampling-text-information"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-6" class="section level2" number="23.1">
<h2>
<span class="header-section-number">23.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-6"><i class="fas fa-link"></i></a>
</h2>
<p>The hands-on exercise for this week focuses on how to collect and/or sample text information.</p>
<p>In this tutorial, you will learn how to:</p>
<ul>
<li>Access text information from online corpora</li>
<li>Query text information using different APIs</li>
<li>Scrape text information programmatically</li>
<li>Transcribe text information from audio</li>
<li>Extract text information from images</li>
</ul>
</div>
<div id="online-corpora" class="section level2" number="23.2">
<h2>
<span class="header-section-number">23.2</span> Online corpora<a class="anchor" aria-label="anchor" href="#online-corpora"><i class="fas fa-link"></i></a>
</h2>
<div id="replication-datasets" class="section level3" number="23.2.1">
<h3>
<span class="header-section-number">23.2.1</span> Replication datasets<a class="anchor" aria-label="anchor" href="#replication-datasets"><i class="fas fa-link"></i></a>
</h3>
<p>There are large numbers of online corpora and replication datasets available to access freely online. We will first access such an example using the <code>dataverse</code> package in R, which allows us to download directly from replication data repositories stored at the <a href="https://dataverse.harvard.edu/">Harvard Dataverse</a>.</p>
<div class="sourceCode" id="cb385"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://iqss.github.io/dataverse-client-r/">dataverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span></code></pre></div>
<p>Let’s take an example dataset in which we might be interested: the UK parliamentary speech data from</p>
<p>We first need to set an en environment variable as so.</p>
<div class="sourceCode" id="cb386"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html">Sys.setenv</a></span><span class="op">(</span><span class="st">"DATAVERSE_SERVER"</span> <span class="op">=</span> <span class="st">"dataverse.harvard.edu"</span><span class="op">)</span></span></code></pre></div>
<p>We can then search out the files that we want by specifying the DOI of the publication data in question. We can find this as a series of numbers and letters that come after “<a href="https://doi.org/" class="uri">https://doi.org/</a>” as shown below.</p>
<div class="inline-figure"><img src="data/sampling/doi.png" style="width:100.0%"></div>
<div class="sourceCode" id="cb387"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://iqss.github.io/dataverse-client-r/reference/get_dataset.html">get_dataset</a></span><span class="op">(</span><span class="st">"10.7910/DVN/QDTLYV"</span><span class="op">)</span></span>
<span><span class="va">dataset</span><span class="op">$</span><span class="va">files</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"filename"</span>, <span class="st">"contentType"</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code>##                  filename                                                             contentType
## 1                 1-uk.do                                              application/x-stata-syntax
## 2            2-ireland.do                                              application/x-stata-syntax
## 3        3-word_clouds.py                                                           text/x-python
## 4              4-trends.R                                                         type/x-r-syntax
## 5  5-predictive_margins.R                                                         type/x-r-syntax
## 6      6-barplot_topics.R                                                         type/x-r-syntax
## 7          7-plot_media.R                                                         type/x-r-syntax
## 8           8-histogram.R                                                         type/x-r-syntax
## 9       commons_stats.tab                                               text/tab-separated-values
## 10      emotive_cloud.tab                                               text/tab-separated-values
## 11    emotive_ireland.tab                                               text/tab-separated-values
## 12         emotive_uk.tab                                               text/tab-separated-values
## 13       ireland_data.csv                                                                text/csv
## 14      neutral_cloud.tab                                               text/tab-separated-values
## 15    neutral_ireland.tab                                               text/tab-separated-values
## 16         neutral_uk.tab                                               text/tab-separated-values
## 17            README.docx application/vnd.openxmlformats-officedocument.wordprocessingml.document
## 18            uk_data.csv                                                                text/csv</code></pre>
<p>We choose to get the UK data from these files, which is listed under “UK_data.csv.” We can then download this directly in the following way (this will take some time as the file size is &gt;1GB).</p>
<div class="sourceCode" id="cb389"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://iqss.github.io/dataverse-client-r/reference/get_dataframe.html">get_dataframe_by_name</a></span><span class="op">(</span></span>
<span>  <span class="st">"uk_data.csv"</span>,</span>
<span>  <span class="st">"10.7910/DVN/QDTLYV"</span>,</span>
<span>  .f <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.delim</a></span><span class="op">(</span><span class="va">x</span>, sep <span class="op">=</span> <span class="st">","</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Of course, we could also download these data manually, by clicking the buttons at the relevant <a href="https://dataverse.harvard.edu/">Harvard Dataverse</a>—but it is sometimes useful to build in every step of your data collection to your code documentation, making the analysis entirely programatically reproducible from start to finish.</p>
<p>Note as well that we don’t have to search out specific datasets that we already know about. We can also use the <code>dataverse</code> package to search datasets or dataverses. We can do this very simply in the following way.</p>
<div class="sourceCode" id="cb390"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://iqss.github.io/dataverse-client-r/reference/dataverse_search.html">dataverse_search</a></span><span class="op">(</span><span class="st">"corpus politics text"</span>, type <span class="op">=</span> <span class="st">"dataset"</span>, per_page <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 10 of 41471 results retrieved</code></pre>
<div class="sourceCode" id="cb392"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">search_results</span><span class="op">[</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code>##                                                                                                  name
## 1                             "A Deeper Look at Interstate War Data: Interstate War Data Version 1.1"
## 2                                                            "Birth Legacies, State Making, and War."
## 3                                "CBS Morning News" Shopping Habits and Lifestyles Poll, January 1989
## 4                        "Common Sense" for Ontario: Defining the New Government's Mandate: June 1995
## 5                                          "Cuadro histórico del General Santa Anna. 2a. parte," 1857
## 6         "Don't Know" Means "Don't Know": DK Responses and the Public's Level of Political Knowledge
## 7                   "El déspota Santa-Anna ante los veteranos de la Independencia," 1844 Diciembre 09
## 8                    "European mood" bi-annual data, EU27 member states (1973-2014), Replication Data
## 9  "Government Partisanship and Electoral Accountability" Political Research Quarterly 72(3): 727-743
## 10                      "I Didn't Lie, I Misspoke": Voters' Responses to Questionable Campaign Claims
##       type                                   url
## 1  dataset    https://doi.org/10.7910/DVN/E2CEP5
## 2  dataset    https://doi.org/10.7910/DVN/EP7DXB
## 3  dataset https://doi.org/10.3886/ICPSR09230.v1
## 4  dataset    https://doi.org/10.5683/SP2/OKNWMZ
## 5  dataset    https://doi.org/10.18738/T8/Z0JH2C
## 6  dataset    https://doi.org/10.7910/DVN/G9NOQO
## 7  dataset    https://doi.org/10.18738/T8/U71QSD
## 8  dataset    https://doi.org/10.7910/DVN/V42M9J
## 9  dataset    https://doi.org/10.7910/DVN/5OG9VV
## 10 dataset    https://doi.org/10.7910/DVN/GE3E8R</code></pre>
</div>
<div id="curated-corpora" class="section level3" number="23.2.2">
<h3>
<span class="header-section-number">23.2.2</span> Curated corpora<a class="anchor" aria-label="anchor" href="#curated-corpora"><i class="fas fa-link"></i></a>
</h3>
<p>There are, of course, many other sources you might go to for text information. I list some of these that might be of interest below:</p>
<ul>
<li>Large English-language corpora: <a href="https://www.corpusdata.org/">https://www.corpusdata.org/</a>
</li>
<li>Wikipedia data dumps: <a href="https://meta.wikimedia.org/wiki/Data_dumps">https://meta.wikimedia.org/wiki/Data_dumps</a>
<ul>
<li>English version of dumps <a href="https://dumps.wikimedia.org/enwiki/">here</a>
</li>
</ul>
</li>
<li>Scottish Corpus of Texts &amp; Speech: <a href="https://www.scottishcorpus.ac.uk/">https://www.scottishcorpus.ac.uk/</a>
</li>
<li>Corpus of Scottish modern writing: <a href="https://www.scottishcorpus.ac.uk/cmsw/">https://www.scottishcorpus.ac.uk/cmsw/</a>
</li>
<li>The Manifesto Corpus: <a href="https://manifesto-project.wzb.eu/information/documents/corpus">https://manifesto-project.wzb.eu/information/documents/corpus</a>
</li>
<li>Reddit Pushshift data: <a href="https://files.pushshift.io/reddit/">https://files.pushshift.io/reddit/</a>
</li>
<li>Mediacloud: <a href="https://mediacloud.org/">https://mediacloud.org/</a>
<ul>
<li>R package: <a href="https://github.com/joon-e/mediacloud">https://github.com/joon-e/mediacloud</a>
</li>
</ul>
</li>
</ul>
<p><strong>Feel free to recommend any further sources and I will add them to this list, which is intended as a growing index of relevant text corpora for social science research!</strong></p>
</div>
</div>
<div id="using-apis" class="section level2" number="23.3">
<h2>
<span class="header-section-number">23.3</span> Using APIs<a class="anchor" aria-label="anchor" href="#using-apis"><i class="fas fa-link"></i></a>
</h2>
<p>To practice these skills, you might want to create a new account for your academic research. But you needn’t create a new account to follow the steps below. You can simply use your own account—if you have one—as using the developer tools will not change anything about your public Twitter account.</p>
<div class="inline-figure"><img src="data/sampling/twitterdev.png" style="width:100.0%"></div>
<p>Before proceeding, we’ll load the remaining packages we will need for this tutorial.</p>
<div class="sourceCode" id="cb394"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span> <span class="co"># loads dplyr, ggplot2, and others</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://docs.ropensci.org/rtweet/">rtweet</a></span><span class="op">)</span> <span class="co"># to query the Twitter API in R</span></span></code></pre></div>
<p>Once you’ve create your new account, or have logged into your existing one, go to the Twitter developer portal log in page <a href="https://developer.twitter.com/en">here</a>.</p>
<p>Click on Apply in the navigation bar on the top right of the page. You’ll be asked “what best describes you?” For the purposes of this tutorial, select academic, and then select student. Fill in all the relevant information and submit your application. Your application will then be reviewed by Twitter before access is granted. This might take hours or days.</p>
<p>Once you have authorization, a new tab will appear in the navigation bar at the top of the develop portal, as below:</p>
<div class="inline-figure"><img src="data/sampling/twitterdev2.png" style="width:100.0%"></div>
<p>Navigate to the developer portal and you will there be able to create a new “app” to query the API. You see in my account that I have several apps for different purposes.</p>
<div class="inline-figure">
<img src="data/sampling/twitterdev3.png" style="width:100.0%">
We can create a new app on this page too. When we click “Create App” we will first be asked to name the app. Most importantly, we will then be given an “API key”; an “API secret key”; and a “Bearer token” as below.</div>
<div class="inline-figure"><img src="data/sampling/twitterdev4.png" style="width:30.0%"></div>
<p>You <strong>MUST</strong> make a record of these. Once you have done so, you can then use these to access the API. Once you have recorded these, navigate to the App setting tabs for the App you’ve created now listed in the Overview tab on the left hand side navigation window.</p>
<div class="inline-figure"><img src="data/sampling/twitterdev5.png" style="width:50.0%"></div>
<p>Navigate to “Keys and tokens” on this page, and click generate in the Access token &amp; secret box as below:</p>
<div class="inline-figure"><img src="data/sampling/twitterdev6.png" style="width:50.0%"></div>
<p>Record these as well. Once you have all of these keys and tokens recorded somewhere safe, you are ready to collect data!</p>
<p>This is pretty simple using the <tt>rtweet</tt> package. Below, we’ll collect the last 50 tweets of the founder of Twitter: Jack Dorsey.</p>
<div class="sourceCode" id="cb395"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">api_key</span> <span class="op">&lt;-</span><span class="st">" XXXXXXXXXXXXXXXXXXXXXXX"</span></span>
<span><span class="va">api_key_secret</span> <span class="op">&lt;-</span> <span class="st">"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span></span>
<span><span class="va">access_token</span> <span class="op">&lt;-</span> <span class="st">"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span></span>
<span><span class="va">access_token_secret</span> <span class="op">&lt;-</span> <span class="st">"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"</span></span>
<span></span>
<span><span class="va">token</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://docs.ropensci.org/rtweet/reference/create_token.html">create_token</a></span><span class="op">(</span></span>
<span>  app <span class="op">=</span> <span class="st">"NAME YOUR APP"</span>,</span>
<span>  consumer_key <span class="op">=</span> <span class="va">api_key</span>,</span>
<span>  consumer_secret <span class="op">=</span> <span class="va">api_key_secret</span>,</span>
<span>  access_token <span class="op">=</span> <span class="va">access_token</span>,</span>
<span>  access_secret <span class="op">=</span> <span class="va">access_token_secret</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">user</span> <span class="op">&lt;-</span> <span class="st">"@jack"</span></span>
<span><span class="va">jacktweets</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://docs.ropensci.org/rtweet/reference/get_timeline.html">get_timeline</a></span><span class="op">(</span><span class="va">user</span>, n <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">jacktweets</span><span class="op">)</span></span></code></pre></div>
<p>Once you have enter your keys, tokens, and key/token secrets, store them with the <code><a href="https://docs.ropensci.org/rtweet/reference/create_token.html">create_token()</a></code> function. Here, we are collecting the last 50 tweets for Jack Dorsey, though you can change this by specifying a higher n—be aware, though, that the maximum you are able to collect with the basic API access is 3200 tweets.</p>
<div class="inline-table"><table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:left;">
created_at
</th>
<th style="text-align:left;">
screen_name
</th>
<th style="text-align:left;">
text
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
2021-02-25 23:36:34
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
Bitcoin, Blockchain and the Black Community - CoinDesk <a href="https://t.co/3KH6W7Rg0Q" class="uri">https://t.co/3KH6W7Rg0Q</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-25 23:32:42
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
<p>Starting in less than an hour! 👇🏾</p>
<p>Tune into <span class="citation">(<a href="#ref-CoinDesk" role="doc-biblioref"><strong>CoinDesk?</strong></a>)</span> TV and watch #CommunityCrypto at 5pm ET</p>
See you then! ✊🏾 <a href="https://t.co/ACnRhdabEy" class="uri">https://t.co/ACnRhdabEy</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-25 04:22:10
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
Crypto art changing lives <a href="https://t.co/yDEQOaA483" class="uri">https://t.co/yDEQOaA483</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-25 03:59:05
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
<a href="https://t.co/2i46RZ6c0A" class="uri">https://t.co/2i46RZ6c0A</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-24 04:47:59
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
<span class="citation">(<a href="#ref-hfangca" role="doc-biblioref"><strong>hfangca?</strong></a>)</span> <span class="citation">(<a href="#ref-OKCoin" role="doc-biblioref"><strong>OKCoin?</strong></a>)</span> <span class="citation">(<a href="#ref-opencryptoorg" role="doc-biblioref"><strong>opencryptoorg?</strong></a>)</span> Thank you for joining!
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-23 17:13:31
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
<span class="citation">(<a href="#ref-bitcoinbrink" role="doc-biblioref"><strong>bitcoinbrink?</strong></a>)</span> 🙏🏼
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-20 02:06:24
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
It’s an honor to help in this important endeavor. All orgs developing in crypto — for-profit or nonprofit, even individuals — should consider joining. There is strength in numbers. <a href="https://t.co/CJo9frhkhJ" class="uri">https://t.co/CJo9frhkhJ</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-20 01:47:23
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
Over 6,600 people submitted their proof-of-work so far. Working to narrow over weekend and will start interviewing board candidates soon.
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-19 20:34:35
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
This is excellent 🧡 <a href="https://t.co/e7ywpoCcxS" class="uri">https://t.co/e7ywpoCcxS</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
2021-02-17 03:47:40
</td>
<td style="text-align:left;">
jack
</td>
<td style="text-align:left;">
learned the most from <a href="https://t.co/GrUoCXanNL" class="uri">https://t.co/GrUoCXanNL</a> and <a href="https://t.co/cz3yYo4UEw" class="uri">https://t.co/cz3yYo4UEw</a>
</td>
</tr>
</tbody>
</table></div>
<p>Now you can play around with the different API calls possible with the <tt>rtweet</tt> package. See the full documentation <a href="https://cran.r-project.org/web/packages/rtweet/rtweet.pdf">here</a> and <a href="https://github.com/ropensci/rtweet">here</a>.</p>
<p>And for those interested, you can my package to collect tweets from the Academic Research Product Track API <a href="https://github.com/cjbarrie/academictwitteR">here</a>.</p>
<p>Getting access to the Academic Research Product Track is a bit more complicated but for more information on how to apply see <a href="https://developer.twitter.com/en/solutions/academic-research/products-for-researchers">here</a>.</p>
<p>In order to use the Twitter Academic Research Product Track you will first need to obtain an authorization token. You will find details about the process of obtaining authorization <a href="https://developer.twitter.com/en/solutions/academic-research/application-info">here</a>.</p>
<p><strong>In order to gain authorization you first need a Twitter account.</strong></p>
<p>First, Twitter will ask for details about your academic profile. Per the documentation linked above, they will ask for the following:</p>
<blockquote>
<p>Your full name as it is appears on your institution’s documentation</p>
<p>Links to webpages that help establish your identity; provide one or more of the following:</p>
<ul>
<li>A link to your profile in your institution’s faculty or student directory</li>
<li>A link to your Google Scholar profile</li>
<li>A link to your research group, lab or departmental website where you are listed</li>
</ul>
<p>Information about your academic institution: its name, country, state, and city</p>
<p>Your department, school, or lab name</p>
<p>Your academic field of study or discipline at this institution</p>
<p>Your current role as an academic (whether you are a graduate student, doctoral candidate, post-doc, professor, research scientist, or other faculty member)</p>
</blockquote>
<p>Twitter will then ask for details of the proposed research project. Here, questions include:</p>
<blockquote>
<ol style="list-style-type: decimal">
<li><p>What is the name of your research project?</p></li>
<li><p>Does this project receive funding from outside your academic institution? If yes, please list all your sources of funding.</p></li>
<li><p>In English, describe your research project. Minimum 200 characters.</p></li>
<li><p>In English, describe how Twitter data via the Twitter API will be used in your research project. Minimum 200 characters.</p></li>
<li><p>In English, describe your methodology for analyzing Twitter data, Tweets, and/or Twitter users. Minimum 200 characters.</p></li>
<li><p>Will your research present Twitter data individually or in aggregate?</p></li>
<li><p>In English, describe how you will share the outcomes of your research (include tools, data, and/or other resources you hope to build and share). Minimum 200 characters.</p></li>
<li><p>Will your analysis make Twitter content or derived information available to a government entity?</p></li>
</ol>
</blockquote>
<p>Once you have gained authorization for your project you will be able to see the new project on your Twitter developer portal.</p>
<p>The Academic Research Product Track permits the user to access larger volumes of data, over a far longer time range, than was previously possible. From the Twitter <a href="https://developer.twitter.com/en/solutions/academic-research/application-info">documentation</a>:</p>
<blockquote>
<p>“The Academic Research product track includes full-archive search, as well as increased access and other v2 endpoints and functionality designed to get more precise and complete data for analyzing the public conversation, at no cost for qualifying researchers. Since the Academic Research track includes specialized, greater levels of access, it is reserved solely for non-commercial use”.</p>
</blockquote>
<p>The new “v2 endpoints” refer to the v2 API, introduced around the same time as the new Academic Research Product Track. Full details of the v2 endpoints are available <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">here</a>.</p>
<p>In summary the Academic Research product track allows the authorized user:</p>
<ol style="list-style-type: decimal">
<li>Access to the full archive of (as-yet-undeleted) tweets published on Twitter</li>
<li>A higher monthly tweet cap (10m–or 20x what was previously possible with the standard v1.1 API)</li>
<li>Ability to access these data with more precise filters permitted by the v2 API</li>
</ol>
<p>If you do get authorization for using the Twitter Academic API, you can then follow the next steps to begin collecting data. Instead of four different keys or secrets, we will have one “bearer token” that we use, associated with one of the apps that we created as above. This is all we then need to begin collecting data.</p>
<p>First we need to load the package into memory as follows.</p>
<div class="sourceCode" id="cb396"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/cjbarrie/academictwitteR">academictwitteR</a></span><span class="op">)</span></span></code></pre></div>
<p>The first task is set authorization credentials with the <code><a href="https://rdrr.io/pkg/academictwitteR/man/set_bearer.html">set_bearer()</a></code> function, which allows the user to store their bearer token in the .Renviron file.</p>
<p>To do so, use:</p>
<div class="sourceCode" id="cb397"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/set_bearer.html">set_bearer</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>and enter authorization credentials as below:</p>
<div class="inline-figure"><img src="data/sampling/TWITTER_BEARER.gif"></div>
<p>This will mean that the bearer token is automatically called during API calls. It also avoids the inadvisable practice of hard-coding authorization credentials into scripts.</p>
<p>The workhorse function is <code><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets()</a></code>, which is able to collect tweets matching a specific search query or all tweets by a specific set of users.</p>
<div class="sourceCode" id="cb398"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tweets</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>    query <span class="op">=</span> <span class="st">"#BlackLivesMatter"</span>,</span>
<span>    start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>    end_tweets <span class="op">=</span> <span class="st">"2020-01-05T00:00:00Z"</span>,</span>
<span>    file <span class="op">=</span> <span class="st">"blmtweets"</span>,</span>
<span>    data_path <span class="op">=</span> <span class="st">"data/"</span>,</span>
<span>    n <span class="op">=</span> <span class="fl">1000000</span>,</span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>Here, we are collecting tweets containing a hashtag related to the Black Lives Matter movement over the period January 1, 2020 to January 5, 2020.</p>
<p>We have also set an upper limit of one million tweets. When collecting large amounts of Twitter data we recommend including a <code>data_path</code> and setting <code>bind_tweets = FALSE</code> such that data is stored as JSON files and can be bound at a later stage upon completion of the API query.</p>
<div class="sourceCode" id="cb399"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tweets</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>    users <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"jack"</span>, <span class="st">"cbarrie"</span><span class="op">)</span>,</span>
<span>    start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>    end_tweets <span class="op">=</span> <span class="st">"2020-01-05T00:00:00Z"</span>,</span>
<span>    file <span class="op">=</span> <span class="st">"blmtweets"</span>,</span>
<span>    n <span class="op">=</span> <span class="fl">1000</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>Whereas here we are not specifying a search query and instead are requesting all tweets by users “jack” and “cbarrie” over the period January 1, 2020 to January 5, 2020. Here, we set an upper limit of 1000 tweets.</p>
<p>The search query and user query arguments can be combined in a single API call as so:</p>
<div class="sourceCode" id="cb400"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>  query <span class="op">=</span> <span class="st">"twitter"</span>,</span>
<span>  users <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cbarrie"</span>, <span class="st">"jack"</span><span class="op">)</span>,</span>
<span>  start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>  end_tweets <span class="op">=</span> <span class="st">"2020-05-01T00:00:00Z"</span>,</span>
<span>  n <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Where here we would be collecting tweets by users “jack” and “cbarrrie” over the period January 1, 2020 to January 5, 2020 containing the word “twitter.”</p>
<div class="sourceCode" id="cb401"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>  query <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"twitter"</span>, <span class="st">"social"</span><span class="op">)</span>,</span>
<span>  users <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cbarrie"</span>, <span class="st">"jack"</span><span class="op">)</span>,</span>
<span>  start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>  end_tweets <span class="op">=</span> <span class="st">"2020-05-01T00:00:00Z"</span>,</span>
<span>  n <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>While here we are collecting tweets by users “jack” and “cbarrrie” over the period January 1, 2020 to January 5, 2020 containing the words “twitter” or “social.”</p>
<p>Note that the “AND” operator is implicit when specifying more than one character string in the query. See <a href="https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query">here</a> for information on building queries for search tweets. Thus, when searching for all elements of a character string, a call may look like:</p>
<div class="sourceCode" id="cb402"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>  query <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"twitter social"</span><span class="op">)</span>,</span>
<span>  users <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cbarrie"</span>, <span class="st">"jack"</span><span class="op">)</span>,</span>
<span>  start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>  end_tweets <span class="op">=</span> <span class="st">"2020-05-01T00:00:00Z"</span>,</span>
<span>  n <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>, which will capture tweets containing <em>both</em> the words “twitter” and “social.” The same logics apply for hashtag queries.</p>
<p>Whereas if we specify our query as separate elements of a character vector like this:</p>
<div class="sourceCode" id="cb403"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>  query <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"twitter"</span>, <span class="st">"social"</span><span class="op">)</span>,</span>
<span>  users <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"cbarrie"</span>, <span class="st">"jack"</span><span class="op">)</span>,</span>
<span>  start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>  end_tweets <span class="op">=</span> <span class="st">"2020-05-01T00:00:00Z"</span>,</span>
<span>  n <span class="op">=</span> <span class="fl">1000</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>, this will be capturing tweets by users “cbarrie” or “jack” containing the words “twitter” <em>or</em> social.</p>
<p>Finally, we may wish to query an exact phrase. To do so, we can either input the phrase in escape quotes, e.g., <code>query ="\"Black Lives Matter\""</code> or we can use the optional parameter <code>exact_phrase = T</code> to search for tweets containing the exact phrase string:</p>
<div class="sourceCode" id="cb404"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tweets</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/academictwitteR/man/get_all_tweets.html">get_all_tweets</a></span><span class="op">(</span></span>
<span>    query <span class="op">=</span> <span class="st">"#BlackLivesMatter"</span>,</span>
<span>    start_tweets <span class="op">=</span> <span class="st">"2020-01-01T00:00:00Z"</span>,</span>
<span>    end_tweets <span class="op">=</span> <span class="st">"2020-01-05T00:00:00Z"</span>,</span>
<span>    file <span class="op">=</span> <span class="st">"blmtweets"</span>,</span>
<span>    data_path <span class="op">=</span> <span class="st">"data/"</span>,</span>
<span>    n <span class="op">=</span> <span class="fl">1000000</span>,</span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>Here, we are collecting tweets containing a hashtag related to the Black Lives Matter movement over the period January 1, 2020 to January 5, 2020.</p>
<p>And the Twitter API is, of course, not the only API out there!</p>
<div id="other-apis-r-packages" class="section level3" number="23.3.1">
<h3>
<span class="header-section-number">23.3.1</span> Other APIs (R packages)<a class="anchor" aria-label="anchor" href="#other-apis-r-packages"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><a href="https://cran.r-project.org/web/packages/manifestoR/index.html">https://cran.r-project.org/web/packages/manifestoR/index.html</a></li>
<li><a href="https://cran.r-project.org/web/packages/vkR/vkR.pdf">https://cran.r-project.org/web/packages/vkR/vkR.pdf</a></li>
<li><a href="https://cran.r-project.org/web/packages/tuber/index.html">https://cran.r-project.org/web/packages/tuber/index.html</a></li>
</ul>
</div>
</div>
<div id="scraping" class="section level2" number="23.4">
<h2>
<span class="header-section-number">23.4</span> Scraping<a class="anchor" aria-label="anchor" href="#scraping"><i class="fas fa-link"></i></a>
</h2>
<p>To practice this skill, we will use a series of webpages on the Internet Archive that host material collected at the Arab Spring protests in Egypt in 2011. The original website can be seen <a href="https://www.tahrirdocuments.org/">here</a> and below.</p>
<div class="inline-figure"><img src="data/sampling/tahrir_page.png" style="width:100.0%"></div>
<p>Before proceeding, we’ll load the remaining packages we will need for this tutorial.</p>
<div class="sourceCode" id="cb405"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span> <span class="co"># loads dplyr, ggplot2, and others</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://github.com/jrnold/ggthemes">ggthemes</a></span><span class="op">)</span> <span class="co"># includes a set of themes to make your visualizations look nice!</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://readr.tidyverse.org">readr</a></span><span class="op">)</span> <span class="co"># more informative and easy way to import data</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://stringr.tidyverse.org">stringr</a></span><span class="op">)</span> <span class="co"># to handle text elements</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rvest.tidyverse.org/">rvest</a></span><span class="op">)</span> <span class="co">#for scraping</span></span></code></pre></div>
<p>We can download the final dataset we will produce with:</p>
<div class="sourceCode" id="cb406"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pamphdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/sampling/pamphlets_formatted_gsheets.csv"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## ── Column specification ───────────────────────────────────────────────────────────────────────────
## cols(
##   title = col_character(),
##   date = col_date(format = ""),
##   year = col_double(),
##   text = col_character(),
##   tags = col_character(),
##   imageurl = col_character(),
##   imgID = col_character(),
##   image = col_character()
## )</code></pre>
<p>You can also view the formatted output of this scraping exercise, alongside images of the documents in question, in Google Sheets <a href="https://docs.google.com/spreadsheets/d/1rg2VTV6uuknpu6u-L5n7kvQ2cQ6e6Js7IHp7CaSKe90/edit?usp=sharing">here</a>.</p>
<p>If you’re working on this document from your own computer (“locally”) you can download the Tahrir documents data in the following way:</p>
<div class="sourceCode" id="cb408"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pamphdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://github.com/cjbarrie/CTA-ED/blob/main/data/sampling/pamphlets_formatted_gsheets.csv"</span><span class="op">)</span></span></code></pre></div>
<p>Let’s have a look at what we will end up producing:</p>
<div class="sourceCode" id="cb409"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">pamphdata</span><span class="op">)</span></span></code></pre></div>
<pre><code>## # A tibble: 6 × 8
##   title                                            date        year text  tags  image…¹ imgID image
##   &lt;chr&gt;                                            &lt;date&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;
## 1 The Season of Anger Sets in Among the Arab Peop… 2011-03-30  2011 The … Soli… https:… imgI… =Arr…
## 2 The Most Important Workers’ Protests             2011-03-30  2011 [Voi… Soli… https:… imgI… &lt;NA&gt; 
## 3 Yes it’s the Workers’ and Employees’ Right to S… 2011-03-30  2011 [Voi… Soli… https:… imgI… &lt;NA&gt; 
## 4 The Revolution is Still Ongoing                  2011-03-30  2011 [Voi… Revo… https:… imgI… &lt;NA&gt; 
## 5 Voice of the Revolution, #3                      2011-03-30  2011 Febr… Revo… https:… imgI… &lt;NA&gt; 
## 6 We Are Still Continuing Until Victory            2011-03-29  2011 We A… Dema… https:… imgI… &lt;NA&gt; 
## # … with abbreviated variable name ¹​imageurl</code></pre>
<p>We are going to return to the Internet Archived webpages to see how we can produce this final formatted dataset. The archived Tahrir Documents webpages can be accessed <a href="https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/">here</a>.</p>
<p>We first want to expect how the contents of each webpage is stored.</p>
<p>When we scroll to the very bottom of the page, we see listed a number of hyperlinks to documents stored by month:</p>
<div class="inline-figure"><img src="data/sampling/tahrir_archives.png"></div>
<p>We will click through the documents stored for March and then click on the top listed pamphlet entitled “The Season of Anger Sets in Among the Arab Peoples.” You can access this <a href="https://wayback.archive-it.org/2358/20120130161341/http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/">here</a>.</p>
<p>We will store this url to inspect the HTML it contains as follows:</p>
<div class="sourceCode" id="cb411"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://wayback.archive-it.org/2358/20120130161341/http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/"</span></span>
<span></span>
<span><span class="va">html</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://xml2.r-lib.org/reference/read_xml.html">read_html</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span></span>
<span></span>
<span><span class="va">html</span></span></code></pre></div>
<pre><code>## {html_document}
## &lt;html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US"&gt;
## [1] &lt;head profile="http://gmpg.org/xfn/11"&gt;\n&lt;!-- Start Wayback Rewrite JS Include --&gt;&lt;script ty ...
## [2] &lt;body&gt;             \n&lt;!--\n     FILE ARCHIVED ON 16:13:41 Jan 30, 2012 AND RETRIEVED FROM TH ...</code></pre>
<p>Well, this isn’t particularly useful. Let’s now see how we can extract the text contained inside.</p>
<div class="sourceCode" id="cb413"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pagetext</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pagetext</span></span></code></pre></div>
<pre><code>## [1] "\nif (window._WBWombatInit) {\n  _wb_uc = new URL(\"http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/\");\n  wbinfo = {}\n  wbinfo.url = \"http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/\";\n  wbinfo.timestamp = \"20120130161341\";\n  wbinfo.request_ts = \"20120130161341\";\n  wbinfo.prefix = \"https://wayback.archive-it.org/2358/\";\n  wbinfo.mod = \"if_\";\n  wbinfo.is_framed = false;\n  wbinfo.is_live = false;\n  wbinfo.coll = \"2358\";\n  wbinfo.proxy_magic = \"\";\n  wbinfo.static_prefix = \"/static/\";\n  wbinfo.enable_auto_fetch = true;\n  wbinfo.auto_fetch_worker_prefix = \"https://wayback.archive-it.org/2358/\";\n  wbinfo.wombat_ts = \"20120130161341\";\n  wbinfo.wombat_sec = \"1327940021\";\n  wbinfo.wombat_scheme = ( _wb_uc.protocol || 'http').replace(/:$/, '');\n  wbinfo.wombat_host = _wb_uc.host;\n  wbinfo.wombat_opts = {\n    no_rewrite_prefixes: [\n                            \"https://wayback.archive-it.org/2358/\",\n                            \"//archive-it.org/\",\n                            \"https://partner.archive-it.org/\",\n                          ]\n  };\n  window._WBWombatInit(wbinfo);\n\n  // variables useful for rulesengine rewrites from old ait-client_rewrite.js\n  WB_RewriteUrl = _wb_wombat.rewrite_url;\n  WB_ExtractOrig = _wb_wombat.extract_orig;\n  WB_wombat_self_location = window.WB_wombat_location\n}\n  The Season of Anger Sets in Among the Arab Peoples//&lt;![CDATA[\n\t// Google Analytics for WordPress by Yoast v4.0.10 | http://yoast.com/wordpress/google-analytics/\n\tvar _gaq = _gaq || [];\n\t_gaq.push(['_setAccount','UA-7521051-7']);\n\t_gaq.push(['_trackPageview']);\n\t(function() {\n\t\tvar ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n\t\tga.src = ('https:' == document.location.protocol ? 'https://wayback.archive-it.org/2358/20120130161341/https://ssl' : 'https://wayback.archive-it.org/2358/20120130161341/http://www') + '.google-analytics.com/ga.js';\n\t\tvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n\t})();\n\t//]]&gt;\nbody { background-color: #ececec; }\n             \n\n\n\n  #wm-media-curtain {\n    display: none !important;\n    width: 100vw !important;\n    height: 100vh !important;\n    grid-template-columns: 5% 90% 5%;\n    z-index: 2000000001 !important;\n    background-color: #000000f7 !important;\n    line-height:normal !important;\n    padding: 0 !important;\n    color: #000 !important;\n    position: fixed !important;\n    top: 0 !important;\n    left: 0 !important;\n    font-size: medium !important;\n    font-family: sans-serif !important;\n    font-weight: normal !important;\n  }\n  #wm-media-prev, #wm-media-next {\n    align-self: center !important;\n    justify-self: center !important;\n    color: #fff !important;\n    font-size: 3rem !important;\n    opacity: 0.3 !important;\n  }\n  #wm-media-prev {\n    grid-column: 1 !important;\n    grid-row: 1 / 3 !important;\n    cursor: pointer !important;\n  }\n  #wm-media-next {\n    grid-column: 3 !important;\n    grid-row: 1 / 3 !important;\n    cursor: pointer !important;\n  }\n  #wm-media-close-button {\n    align-self: start !important;\n    justify-self: center !important;\n    color: #fff !important;\n    font-size: 3rem !important;\n    opacity: 0.3 !important;\n    grid-column: 3 !important;\n    grid-row: 1 !important;\n    cursor: pointer !important;\n  }\n  #wm-media-close-button:hover, #wm-media-close-button:active,\n  #wm-media-close-button:focus, #wm-media-prev:hover,\n  #wm-media-prev:active, #wm-media-prev:focus, #wm-media-next:hover,\n  #wm-media-next:active, #wm-media-next:focus {\n    opacity: 0.9 !important;\n  }\n  #wm-media-player-container {\n    align-self: center !important;\n    justify-self: center !important;\n    color: #fff !important;\n    grid-row: 1 / 3 !important;\n    grid-column: 2 !important;\n  }\n  #wm-media-page-number {\n    align-self: end !important;\n    justify-self: center !important;\n    color: #fff !important;\n    grid-row: 2 !important;\n    grid-column: 2 !important;\n    padding-bottom: 3vh !important;\n  }\n  #wm-media-title, #wm-media-description {\n    /* width: 50vw !important; */\n    margin: 1em auto !important;\n  }\n  #wm-media-title {\n    font-weight: bold !important;\n  }\n\n  &lt;\n  \n     \n     \n     \n  \n   \n  \n    ×\n  &gt;\n\n\n\n#wm-disclaim {\ndisplay:block;\nline-height:normal !important;\nborder:1px solid #000 !important;\npadding:5px !important;\nposition:relative !important;\nz-index: 2147483643 !important;\ncolor:#000 !important;\n\nbackground-color:lightYellow !important;\n\nfont-size:medium !important;\nfont-family:sans-serif !important;\nfont-weight:normal !important;\ntext-align:center !important;\n}\n\n#wm-disclaim a {\ncolor:#00f !important;\ntext-decoration:underline !important;\nfont-size:medium !important;\nfont-weight:normal !important;\n}\n\n#wm-disclaim a:hover {\nbackground-color: transparent !important;\n}\n\n#wm-disclaim-hide {\nfloat:right !important;\nmargin:0 0 5px 5px !important;\nborder:1px solid #ccc !important;\npadding:1px 5px !important;\ncursor:default !important;\nfont-size:x-small !important;\nfont-weight:bold !important;\ncolor:#666 !important;\n}\n#wm-disclaim-hide:hover {\nborder:1px outset #ccc !important;\n}\n#wm-disclaim-hide:focus, #wm-disclaim-hide:active {\nborder:1px inset #ccc !important;\n}\n\n#wm-disclaim-img {\nmargin-top: -8px !important;\nfloat: left !important;\nvertical-align:middle !important;\npadding: 0px !important;\n}\n\nhide\n\nYou are viewing an archived web page collected  at the request of American University in Cairo  using Archive-It. This page was captured  on 16:13:41 Jan 30, 2012,\nand is part of the Egypt Politics and Revolution collection.\nThe information on this web page may be out of date. See All versions of this archived page.\nLoading media information\n\n                Enable QA\n\nView Missing URLs\n\n\n//&lt;![CDATA[\n//lazily loading AIT metadata link generation script\nvar lazyLoader = function(evt)\n{\n  document.getElementById('lazyScript').src = 'https://partner.archive-it.org/metadata_link/2358/http%3A//www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/';\n  document.getElementById('loadMissingCountScript').src = 'https://partner.archive-it.org/missing_url_record?getJS=true&amp;type=count&amp;collId=2358&amp;checkBefore=20221223153350&amp;cPage=http%3A%2F%2Fwww.tahrirdocuments.org%2F2011%2F03%2Fvoice-of-the-revolution-3-page-2%2F&amp;timestamp=20120130161341';\n};\n\n//ie8 and below do not support addEventListener\nif (navigator.appName.indexOf('MSIE 7') &gt; 0){\n  //alert(\"msie\");\n}\n\nif (window.addEventListener){\n  window.addEventListener(\"load\", lazyLoader, true);\n} else if (window.attachEvent){\n  window.attachEvent(\"onload\", lazyLoader);\n}\n//]]&gt;\n\nvar disclaimBanner = document.getElementById(\"wm-disclaim\");\nif(disclaimBanner != null) {\n  disclaimElement(disclaimBanner);\n}\n\nfunction fixUpWBBanner() {\n  var wb_banner = document.getElementById(\"wm-disclaim\");\n\n  if (wb_banner) {\n    if (document.body.firstChild !== wb_banner) {\n      document.body.insertBefore(wb_banner, document.body.firstChild);\n    }\n  }\n}\n\nsetInterval(fixUpWBBanner, 2000);\n\n  var __wmAllMedia = [];\n  var __wmArchivedMedia = [];\n  var __wmPlayerIndex = -1;\n\n  function __wmMediaNext() {\n    if (__wmPlayerIndex + 1 &lt; __wmArchivedMedia.length) {\n      __wmPlayerIndex++;\n      __wmUpdateTheaterState();\n    }\n  }\n\n  function __wmMediaPrev() {\n    if (__wmPlayerIndex &gt; 0) {\n      __wmPlayerIndex--;\n      __wmUpdateTheaterState();\n    }\n  }\n\n  function __wmUpdateTheaterState() {\n    var activeMedia = __wmArchivedMedia[__wmPlayerIndex];\n\n    if (activeMedia.title) {\n      document.getElementById(\"wm-media-title\").textContent = activeMedia.title;\n    }\n    if (activeMedia.description) {\n      document.getElementById(\"wm-media-description\").textContent = activeMedia.description;\n    }\n    document.getElementById(\"wm-media-page-number\").textContent =\n      (__wmPlayerIndex + 1) + \" of \" + __wmArchivedMedia.length;\n\n    var newPlayerE;\n    if (activeMedia.isAudio) {\n      newPlayerE = document.createElement(\"audio\");\n    } else {\n      newPlayerE = document.createElement(\"video\");\n      if (activeMedia.wbThumb) {\n        newPlayerE.setAttribute(\"poster\", activeMedia.wbThumb);\n      }\n      newPlayerE.addEventListener(\"loadeddata\", function(e) {\n        document.getElementById(\"wm-media-title\").style.setProperty(\"width\", newPlayerE.videoWidth + \"px\", \"important\");\n        document.getElementById(\"wm-media-description\").style.setProperty(\"width\", newPlayerE.videoWidth + \"px\", \"important\");\n      });\n    }\n    newPlayerE.id = \"wm-media-player\";\n    newPlayerE.setAttribute(\"controls\", \"true\");\n\n    var oldPlayerE = document.getElementById(\"wm-media-player\");\n\n    newPlayerE.addEventListener(\"error\", function(e) {\n      if (newPlayerE.error) { // sometimes this event fires for no reason???\n        var errorE = document.createElement(\"div\");\n        errorE.id = \"wm-media-player\";\n        errorE.textContent = \"Failed to load media (it may not have been captured). \";\n        var linkE = document.createElement(\"a\");\n        linkE.setAttribute(\"href\", activeMedia.wbUrl);\n        linkE.textContent = \"Details\";\n        errorE.appendChild(linkE);\n        var oldPlayerE = document.getElementById(\"wm-media-player\");\n        oldPlayerE.parentElement.replaceChild(errorE, oldPlayerE);\n      }\n    });\n\n    newPlayerE.src = activeMedia.wbUrl;\n    var oldPlayerE = document.getElementById(\"wm-media-player\");\n    oldPlayerE.parentElement.replaceChild(newPlayerE, oldPlayerE);\n\n    if (__wmPlayerIndex &gt; 0) {\n      document.getElementById(\"wm-media-prev\").style.setProperty(\"display\", \"initial\", \"important\");\n    } else {\n      document.getElementById(\"wm-media-prev\").style.setProperty(\"display\", \"none\", \"important\");\n    }\n\n    if (__wmPlayerIndex + 1 &lt; __wmArchivedMedia.length) {\n      document.getElementById(\"wm-media-next\").style.setProperty(\"display\", \"initial\", \"important\");\n    } else {\n      document.getElementById(\"wm-media-next\").style.setProperty(\"display\", \"none\", \"important\");\n    }\n  }\n\n(function() {\n  var mediaInfoLoaded = false;\n  var mediaPlaced = false;\n  var pageUrl = 'http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/';\n  var ydlJsonUrl = 'https://wayback.archive-it.org/2358/20120130161341/youtube-dl:http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/';\n  var totalAudio;\n  var totalVideo;\n  var archivedAudio;\n  var archivedVideo;\n\n  function countEndingDots(s) {\n    var i = s.length - 1;\n    var count = 0;\n    while (i &gt;= 0 &amp;&amp; s[i] == '.') {\n      count += 1;\n      i -= 1;\n    }\n    return count;\n  }\n\n  function updateButtonWhileLoading() {\n    var oldText = document.getElementById('wm-media-button').textContent;\n    var oldDots = countEndingDots(oldText);\n    var newText;\n    if (oldDots &gt;= 3) {\n      newText = oldText.substring(0, oldText.length - oldDots);\n    } else {\n      newText = oldText + \".\";\n    }\n    document.getElementById('wm-media-button').textContent = newText;\n\n  }\n  var buttonUpdater = setInterval(updateButtonWhileLoading, 500);\n\n  function finalizeButton() {\n    clearInterval(buttonUpdater);\n    // \"Found 5 archived media items out of 5 total in page. Play Archived Media\"\n    var text = \"Found \" + __wmArchivedMedia.length + \" archived media \"\n      + (__wmArchivedMedia.length == 1 ? \"item\" : \"items\") + \" out of \"\n      + __wmAllMedia.length + \" total on this page. \";\n    var e = document.getElementById(\"wm-media-button\");\n    e.textContent = text;\n    e.style.setProperty(\"color\", \"#000\", \"important\");\n    if (__wmArchivedMedia &amp;&amp; __wmArchivedMedia.length) {\n      var playE = document.createElement(\"span\");\n      playE.textContent = \"▶️\";\n      playE.style.setProperty(\"cursor\", \"pointer\", \"important\");\n      playE.addEventListener(\"click\", function(e) {\n        document.getElementById(\"wm-media-curtain\").style.setProperty(\"display\", \"grid\", \"important\");\n      });\n      e.appendChild(playE);\n    }\n  }\n\n  function placeMediaOnPageIfReady(e) {\n    console.log(e.type + \" document.readyState=\" + document.readyState);\n    if (e.type === \"mediaInfoLoaded\") {\n      mediaInfoLoaded = true;\n    }\n    if (!mediaPlaced &amp;&amp; mediaInfoLoaded &amp;&amp; document.readyState === \"complete\") {\n      mediaPlaced = true;\n      if (__wmArchivedMedia &amp;&amp; __wmArchivedMedia.length) {\n        placeMediaOnPage(__wmArchivedMedia)\n      }\n    }\n  }\n  document.addEventListener(\"mediaInfoLoaded\", placeMediaOnPageIfReady);\n  document.addEventListener(\"readystatechange\", placeMediaOnPageIfReady);\n\n  function prepareMedia() {\n    window.fetch(ydlJsonUrl)\n      .then(function(response) {\n        return response.json();\n      })\n      .catch(function(e) {\n        return null;\n      })\n      .then(function(ydlJson) {\n        if (ydlJson) {\n          __wmAllMedia = enumerateMedia(ydlJson);\n        }\n        return __wmAllMedia;\n      })\n      .then(function(allMedia) {\n        var allMediaPromises = [];\n        if (allMedia &amp;&amp; allMedia.length) {\n          allMediaPromises = checkIfArchived(allMedia);\n        }\n        return allMediaPromises;\n      })\n      .then(function(allMedia) {   // promises are resolved now\n        __wmAllMedia = allMedia;\n        if (allMedia &amp;&amp; allMedia.length) {\n          __wmArchivedMedia = allMedia.filter(m =&gt; m.isArchived);\n        }\n        document.dispatchEvent(new Event(\"mediaInfoLoaded\"));\n        return __wmArchivedMedia;\n      })\n      .then(function(archivedMedia) {\n        if (archivedMedia &amp;&amp; archivedMedia.length) {\n          __wmPlayerIndex = 0;\n          __wmUpdateTheaterState();\n        }\n        return archivedMedia;\n      })\n      .then(function(archivedMedia) {\n        finalizeButton();\n      })\n      .catch(function(err) {\n        console.warn(\"error loading or setting up media stuff\", err);\n      });\n\n    document.addEventListener('keydown', function(e) {\n      if (e.keyCode == 27) { // esc\n        document.getElementById('wm-media-curtain').style.setProperty('display', 'none', 'important');\n      } else if (e.keyCode == 37) { // left\n        __wmMediaPrev();\n      } else if (e.keyCode == 39) { // right\n        __wmMediaNext();\n      }\n    });\n  }\n\n  function enumerateMedia(ydlJson) {\n    var entries = ydlJson.entries || [ydlJson];\n    var media = [];\n\n    for (var i = 0; i &lt; entries.length; i++) {\n      var entry = entries[i];\n      var url = entry.url.slice(entry.url.indexOf('/http')+1);\n      if (entry.protocol != \"https\" &amp;&amp; entry.protocol != \"http\") {\n        var nnnnn = String(i + 1).padStart(5, \"0\");\n        url = entry.webpage_url.slice(entry.webpage_url.indexOf('/http')+1);\n        url = \"youtube-dl:\" + nnnnn + \":\" + url;\n      }\n      media.push({\n        liveUrl: url,\n        wbUrl: ydlJsonUrl.replace(/youtube-dl:.*/, url),\n        isAudio: entry.format &amp;&amp; entry.format.includes(\"audio only\"),\n        width: entry.width,\n        height: entry.height,\n        wbThumb: ydlJsonUrl.replace(/youtube-dl:.*/, entry.thumbnail.slice(entry.thumbnail.indexOf('/http')+1)),\n        title: entry.title,\n        description: entry.description\n      });\n    }\n\n    return media;\n  }\n\n  /* sets isArchived: true/false for each media element */\n  function checkIfArchived(media) {\n    var promises = [];\n    for (var i = 0; i &lt; media.length; i++) {\n      var promise = (function(mediaItem) {\n        return window.fetch(mediaItem.wbUrl, {method: \"HEAD\"})\n          .then(function(response) {\n            mediaItem.isArchived = response.ok;\n            return mediaItem;\n          });\n      })(media[i]);\n      promises.push(promise);\n    }\n    var allPromise = Promise.all(promises); // wait for all to resolve\n    return allPromise;\n  }\n\n  function findElementsToReplace() {\n    var result = [];\n    var elements = document.querySelectorAll(\"audio,video,object,embed,iframe\");\n    for (var i = 0; i &lt; elements.length; i++) {\n      var e = elements[i];\n      if (e.id == \"wm-media-player\") {\n        continue; // don't replace lightbox player!\n      } else if (e.tagName == \"IFRAME\") {\n        if (e.src.indexOf(\"youtube.com/embed/\") &gt; 0 || e.src.indexOf(\"player.vimeo.com/video\") &gt; 0) {\n          result.push(e);\n        }\n      } else {\n        result.push(e);\n      }\n    }\n    return result;\n  }\n\n  function placeMediaOnPage(media) {\n    var elementsToReplace = findElementsToReplace();\n    for (var i = 0; i &lt; elementsToReplace.length &amp;&amp; i &lt; media.length; i++) {\n      if (!media[i].isArchived)\n        continue;\n\n      var mediaE = document.createElement(!media[i].isAudio ? \"video\" : \"audio\");\n      mediaE.setAttribute(\"controls\", \"true\");\n      // mediaE.setAttribute(\"style\", \"width: 100%; height: 100%\");\n      mediaE.setAttribute(\"style\", \"width: 100%; height: auto\");\n      mediaE.src = media[i].wbUrl;\n\n      elementsToReplace[i].parentElement.replaceChild(mediaE, elementsToReplace[i]);\n    }\n  }\n\n  prepareMedia();\n})();\n\n\n\n  \n    \n\n      \n        \n      \n            \n       \n\n    \n  \n  \n  \n    \n\n\n      \n      \n      About\nRevolution\nLogistics\n\tRevolutionary Newspapers\n\tDemands\n\tCalls to Protest\n\nPolitics\nWafd Party\n\tThe Popular Committees for the Defense of the Revolution\n\tThe Party of the Popular Socialist Alliance\n\tThe Muslim Brotherhood\n\tThe National Progressive Unionist Party (Hizb al-Tagammu’)\n\tThe Justice Party\n\tOther Parties\n\tThe Egyptian Communist Party\n\tCandidates\n\nSolidarity\nWorkers\n\tUnions\n\tPalestine\n\tMovements\n\tLibya\n\nCulture\nPoetry\n\tMedia\n\tSigns from Tahrir\n\tHealth\n\tFiction\n\nConstitution\nMarch Referendum\n\tTheory\n\tDostour Newsletters\n\tConstitution First Movement\n\nRegime\nMubarak and Family\n\tPolice\n\tPrisoners\n\tSecurity Forces\n\nReligion\nAl-Azhar\n\tCoptic Christians\n\tFamily\n\tMoral Conduct\n\tSalafism\n\tSectarian Strife\n\n\n      \n       \n\n       \n\n    \n  \n  \n  \n    \n\n      \n      \n            \n        \n        \n                        \n            The Season of Anger Sets in Among the Arab Peoples\n            \n            \n            \n              March 30, 2011 9:43 pm                                Solidarity                no comments\n               \n            \n            \n            \n            \n            \n            \n\nClick here to download the original.\nThe Season of Anger Sets in Among the Arab Peoples\n \nA member of the Algerian opposition warned the Arab rulers that the Tunisian revolution would initiate a revolutionary tsunami phenomenon that would sweep away their thrones. At the beginning of last December, the end of the dictatorial regimes began with successive protests against high prices in Algeria and Jordan. Then the Tunisian revolution demanded the fall of the regime. Algeria caught the ball of flames, and protests ignited again after having calmed for a time. Then after the Tunisian president was expelled, the revolution reached Egypt. And when Egyptians deposed Mubarak, the sparks proceeded to Algeria, Jordan, Yemen, Bahrain, and then Libya.\n \nThe issue is not one of infection; rather, the subjugated peoples discovered the potential of their own free will. The revolution in one country inspired the populations in other countries, for people imprison themselves in waiting, hoping and yearning, until their spirits emerge carrying the roar of anger that shakes thrones. Every population transfers the experience of other revolutions, borrowing their slogans—’the people want the fall of the regime,’ and ‘peaceful, peaceful’—and their tactics, like the Friday of Anger in Jordan and sit-ins held in major squares located in middle of the capital, such as Egypt’s Tahrir Square. Tunisian revolutionaries contacted Egyptians, providing them with some tactics to beat the regime’s machine, like spraying the windshields of armored cars with colors to paralyze and get the better of them.\n \nBeyond inspiration and transmitting experience, there is also solidarity, for the Tunisian revolution’s victory celebrations spread to Jordan and Egypt. And most of the Arab peoples participated in Egypt’s joy. There were many moving scenes, like the singing of the national anthem and the distribution of sweets and drinks in Jordan and Gaza in celebration of Mubarak’s deposal.\n \nHowever, the regimes that consolidate their interests over and against the people’s also rely on one another and exchange their experiences with oppression and harassment. And now confrontations are raging in Bahrain, Yemen, and Libya as mummified regimes committing increased acts of violence and brutal murder against the protesters. Just as Egypt’s extinct regime did, they use thugs with soft weaponry to transform the scene into bloody chaos. Meanwhile, Israel threatens chaos at the regional level in support of its spies, the Arab rulers, since the one who benefits most from the bowing down of the Arab peoples and their backwardness is none other than Israel.\n \n\nThe solidarity and support of the Arab revolutions for each other is the destiny of the Arab region and the only way to protect the interests and wealth of its peoples.  With the extinct regime issuing threats—as if from another world—that Omar Suleiman, Mubarak, or Ria and Sikina will return, the duty to protect our revolution has doubled. Our resistance won’t simply bring about complete, permanent victory for our own revolution; it will also support the revolutions of other populations who support us in turn. This is our duty and our destiny. For the populations who were long patient, the path of regression to what came before was no longer available. Their victory will soon be achieved through their resistance and free will.\n\n \n________________________\nAcquired March 2011\nTranslated by Yasmeen Mekawy\nTranslation reviewed by Emily Drumsta\n \n \nRelated posts:Call for the Military to Impeach MubarakA Very Important Proposal from the Coalition of the Youth of the Revolution in the City of Matai–al-...The Struggle Movement            \t\t\t\t                \n            \n            \n             \n            \n                        \n                 Share this post\n                    \n                    \n                    \n                    \n                    \n                    \n                    \n                    \n                  \n            \n                                \n        \n        \n         \n        \n        « The Most Important Workers’ Protests The Popular Alliance Party: Foundational Declaration »         \n        \n\n\n\n\n\n\n\n\n\n            \n      \n      \n      \n      \n                \n        Follow Us on Facebook &amp; Twitter About\t\t\tTahrir Documents is an ongoing effort to archive and translate activist papers from the 2011 Egyptian uprising and its aftermath. Materials are collected from demonstrations in Cairo’s Tahrir Square and published in complete English translation alongside scans of the original documents. The project is not affiliated with any political organization, Egyptian or otherwise.\nFor more information please contact tahrirdocuments@gmail.com\n\n\t\t CategoriesAl-Azhar\nCalls to Protest\nCandidates\nConstitution\nConstitution First Movement\nCulture\nDemands\nDostour Newsletters\nFamily\nFiction\nHealth\nLibya\nLogistics\nMarch Referendum\nMedia\nMilitary\nMilitary Tribunals\nMoral Conduct\nMovements\nMubarak and Family\nOther Parties\nPalestine\nPoetry\nPolice\nPolitics\nPrisoners\nRegime\nReligion\nRevolution\nRevolutionary Newspapers\nSalafism\nSectarian Strife\nSecurity Forces\nSigns from Tahrir\nSolidarity\nThe Egyptian Communist Party\nThe Justice Party\nThe Muslim Brotherhood\nThe National Progressive Unionist Party (Hizb al-Tagammu')\nTheory\nThe Party of the Popular Socialist Alliance\nThe Popular Committees for the Defense of the Revolution\nUnions\nWafd Party\nWorkers\n           \n      \n      \n      \n       \n\n    \n  \n\n\n  \n     \n    \n\n      \n\n      Archives\t\tJanuary 2012\n\tDecember 2011\n\tNovember 2011\n\tOctober 2011\n\tSeptember 2011\n\tAugust 2011\n\tJuly 2011\n\tJune 2011\n\tMay 2011\n\tApril 2011\n\tMarch 2011\n\t\t        \n\n\t   \n\t   \n\t   \n\t     \n\t     Tahrir Documents\t\tAbout\nContact\n\t\t \t      \n\t     \n\t   \n\t   \n\t   \n\t     \n\t      \t      \n\t     \n\t   \n\n\t   \n\t     \n\t     Search\n\tSearch for:\n\t\n\t \t      \n\t     \n\t   \n\t   \n\t    \n\n    \n  \n  \n  \n    \n      Designed by \n      Copyright © 2012 Tahrir Documents. All rights reserved.\n    \n  \n    \n\n\n\n\n  var _gaq = _gaq || [];\n  _gaq.push(['_setAccount', 'UA-7521051-7']);\n  _gaq.push(['_trackPageview']);\n\n  (function() {\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n    ga.src = ('https:' == document.location.protocol ? 'https://wayback.archive-it.org/2358/20120130161341/https://ssl' : 'https://wayback.archive-it.org/2358/20120130161341/http://www') + '.google-analytics.com/ga.js';\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n  })();\n\n"</code></pre>
<p>Well this looks pretty terrifying now…</p>
<p>We need a way of quickly identifying where the relevant text is so that we can specify this when we are scraping. The most widely-used tool to achieve this is the “Selector Gadget” Chrome Extension. You can add this to your browser for free <a href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en">here</a>.</p>
<p>The tool works by allowing the user to point and click on elements of a webpage (or “CSS selectors”). Unlike alternatives, such as “Inspect Element” browser tools, we are easily able to see how the webpage item is contained within CSS selectors (rather than HTML tags alone), which is easier to parse.</p>
<p>We can do this with our Tahrir documents as below:</p>
<div class="inline-figure"><img src="data/sampling/gifcap4.gif" style="width:100.0%"></div>
<p>So now we know that the main text of the translated document is contained between “p” HTML tags. To identify the text between these HTML tags we can run:</p>
<div class="sourceCode" id="cb415"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pagetext</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="st">"p"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pagetext</span></span></code></pre></div>
<pre><code>##  [1] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
##  [2] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
##  [3] "Click here to download the original."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
##  [4] "The Season of Anger Sets in Among the Arab Peoples"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         
##  [5] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
##  [6] "A member of the Algerian opposition warned the Arab rulers that the Tunisian revolution would initiate a revolutionary tsunami phenomenon that would sweep away their thrones. At the beginning of last December, the end of the dictatorial regimes began with successive protests against high prices in Algeria and Jordan. Then the Tunisian revolution demanded the fall of the regime. Algeria caught the ball of flames, and protests ignited again after having calmed for a time. Then after the Tunisian president was expelled, the revolution reached Egypt. And when Egyptians deposed Mubarak, the sparks proceeded to Algeria, Jordan, Yemen, Bahrain, and then Libya."                                                                                                                                                                                      
##  [7] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
##  [8] "The issue is not one of infection; rather, the subjugated peoples discovered the potential of their own free will. The revolution in one country inspired the populations in other countries, for people imprison themselves in waiting, hoping and yearning, until their spirits emerge carrying the roar of anger that shakes thrones. Every population transfers the experience of other revolutions, borrowing their slogans—’the people want the fall of the regime,’ and ‘peaceful, peaceful’—and their tactics, like the Friday of Anger in Jordan and sit-ins held in major squares located in middle of the capital, such as Egypt’s Tahrir Square. Tunisian revolutionaries contacted Egyptians, providing them with some tactics to beat the regime’s machine, like spraying the windshields of armored cars with colors to paralyze and get the better of them."
##  [9] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [10] "Beyond inspiration and transmitting experience, there is also solidarity, for the Tunisian revolution’s victory celebrations spread to Jordan and Egypt. And most of the Arab peoples participated in Egypt’s joy. There were many moving scenes, like the singing of the national anthem and the distribution of sweets and drinks in Jordan and Gaza in celebration of Mubarak’s deposal."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
## [11] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [12] "However, the regimes that consolidate their interests over and against the people’s also rely on one another and exchange their experiences with oppression and harassment. And now confrontations are raging in Bahrain, Yemen, and Libya as mummified regimes committing increased acts of violence and brutal murder against the protesters. Just as Egypt’s extinct regime did, they use thugs with soft weaponry to transform the scene into bloody chaos. Meanwhile, Israel threatens chaos at the regional level in support of its spies, the Arab rulers, since the one who benefits most from the bowing down of the Arab peoples and their backwardness is none other than Israel."                                                                                                                                                                               
## [13] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [14] "The solidarity and support of the Arab revolutions for each other is the destiny of the Arab region and the only way to protect the interests and wealth of its peoples.  With the extinct regime issuing threats—as if from another world—that Omar Suleiman, Mubarak, or Ria and Sikina will return, the duty to protect our revolution has doubled. Our resistance won’t simply bring about complete, permanent victory for our own revolution; it will also support the revolutions of other populations who support us in turn. This is our duty and our destiny. For the populations who were long patient, the path of regression to what came before was no longer available. Their victory will soon be achieved through their resistance and free will."                                                                                                          
## [15] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [16] "________________________"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
## [17] "Acquired March 2011"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
## [18] "Translated by Yasmeen Mekawy"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
## [19] "Translation reviewed by Emily Drumsta"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
## [20] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [21] ""                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
## [22] "« The Most Important Workers’ Protests The Popular Alliance Party: Foundational Declaration »"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
## [23] "Tahrir Documents is an ongoing effort to archive and translate activist papers from the 2011 Egyptian uprising and its aftermath. Materials are collected from demonstrations in Cairo’s Tahrir Square and published in complete English translation alongside scans of the original documents. The project is not affiliated with any political organization, Egyptian or otherwise."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
## [24] "For more information please contact tahrirdocuments@gmail.com"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              
## [25] "Designed by"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
## [26] "Copyright © 2012 Tahrir Documents. All rights reserved."</code></pre>
<p>, which looks quite a lot more manageable…!</p>
<p>What is happening here? Essentially, the <code><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements()</a></code> function is scanning the page and collecting all HTML elements contained between <code>&lt;p&gt;</code> tags, which we collect using the “p” CSS selector. We are then just grabbing the text contained in this part of the page with the <code><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text()</a></code> function.</p>
<p>So this gives us one way of capturing the text, but what about if we wanted to get other elements of the document, for example the date or the tags attributed to each document? Well we can do the same thing here too. Let’s take the example of getting the date:</p>
<div class="inline-figure"><img src="data/sampling/gifcap5.gif" style="width:100.0%"></div>
<p>We see here that the date is identified by the “.calendar” CSS selector and so we enter this into the same <code><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements()</a></code> function as before:</p>
<div class="sourceCode" id="cb417"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pagedate</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="st">".calendar"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pagedate</span></span></code></pre></div>
<pre><code>## [1] "March 30, 2011 9:43 pm"</code></pre>
<p>Of course, this is all well and good, but we also need a way of doing this at scale—we can’t just keep repeating the same process for every page we find as this wouldn’t be much quicker than just copy pasting. So how can we do this? Well we need first to understand the URL structure of the website in question.</p>
<p>When we scroll down the page we see listed a number of documents. Each of these directs to an individual pamphlet distributed at protests during the 2011 Egyptian Revolution.</p>
<p>Click on one of these and see how the URL changes.</p>
<p>We see that if our starting URL was:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130135111/http://www.tahrirdocuments.org/</code></pre>
<p>Then if we click on March 2011, the first month for which we have documents, we see that the url becomes:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/</code></pre>
<p>, for August 2011 it becomes:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130142155/http://www.tahrirdocuments.org/2011/08/</code></pre>
<p>, and for January 2012 it becomes:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130142014/http://www.tahrirdocuments.org/2012/01/</code></pre>
<p>We notice that for each month, the URL changes with the addition of month and year between back slashes at the end or the URL. In the next section, we will go through how to efficiently create a set of URLs to loop through and retrieve the information contained in each individual webpage.</p>
<p>We are going to want to retrieve the text of documents archived for each month. As such, our first task is to store each of these webpages as a series of strings. We could do this manually by, for example, pasting year and month strings to the end of each URL for each month from March, 2011 to January, 2012:</p>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/"</span></span>
<span></span>
<span><span class="va">url1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/03/"</span><span class="op">)</span></span>
<span><span class="va">url2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/04/"</span><span class="op">)</span></span>
<span><span class="va">url3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/04/"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">#etc...</span></span>
<span></span>
<span><span class="va">urls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">url1</span>, <span class="va">url2</span>, <span class="va">url3</span><span class="op">)</span></span></code></pre></div>
<p>But this wouldn’t be particularly efficient…</p>
<p>Instead, we can wrap all of this in a loop.</p>
<div class="sourceCode" id="cb424"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">urls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">3</span><span class="op">:</span><span class="fl">13</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/"</span></span>
<span>  <span class="va">newurl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">i</span> <span class="op">&lt;</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/0"</span>,<span class="va">i</span>,<span class="st">"/"</span><span class="op">)</span>, </span>
<span>                   <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">i</span><span class="op">&gt;=</span><span class="fl">10</span> <span class="op">&amp;</span> <span class="va">i</span><span class="op">&lt;=</span><span class="fl">12</span> , <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/"</span>,<span class="va">i</span>,<span class="st">"/"</span><span class="op">)</span>, </span>
<span>                          <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2012/01/"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">urls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">urls</span>, <span class="va">newurl</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>What’s going on here? Well, we are first specifying the starting URL as above. We are then iterating through the numbers 3 to 13. And we are telling R to take the new URL and then, depending on the number in the loop we are on, to take the base starting url— <a href="https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/" class="uri">https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/</a> — and to paste on the end of it the string “2011/0”, then the number of the loop we are on, and then “/”. So, for the first “i” in the loop—the number 3—then we are effectively calling the equivalent of:</p>
<div class="sourceCode" id="cb425"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">i</span> <span class="op">&lt;-</span> <span class="fl">3</span></span>
<span></span>
<span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/"</span></span>
<span></span>
<span><span class="va">newurl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"2011/0"</span>,<span class="va">i</span>,<span class="st">"/"</span><span class="op">)</span></span></code></pre></div>
<p>Which gives:</p>
<pre><code>## [1] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/"</code></pre>
<p>In the above, the <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> commands are simply telling R: if i (the number of the loop we are on) is less than 10 then <code>paste0(url,"2011/0",i,"/")</code>; i.e., if i is less than 10 then paste “2011/0”, then “i” and then “/”. So for the number 3 this becomes:</p>
<p><code>"https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/"</code></p>
<p>, and for the number 4 this becomes</p>
<p><code>"https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/04/"</code></p>
<p>If, however, <code>i&gt;=10 &amp; i&lt;=12</code> (i is greater than or equal to 10 and less than or equal to 12) then we are calling <code>paste0(url,"2011/",i,"/")</code> because here we do not need the first “0” in the months.</p>
<p>Finally, if (else) i is greater than 12 then we are calling <code>paste0(url,"2012/01/")</code>. For this last call, notice, we do not have to specify whether i is greater than or equal to 12 because we are wrapping everything in <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> commands. With <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> calls like this, we are telling R if x “meets condition” then do y, otherwise do z. When we are wrapping multiple <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> calls within each other, we are effectively telling R if x “meets condition” then do y, or if x “meets other condition” then do z, otherwise do a. So here, the “otherwise do a” part of the <code><a href="https://rdrr.io/r/base/ifelse.html">ifelse()</a></code> calls is saying: if i is not less than 10, and is not between 10 and 12, then paste “2012/01/” to the end of the URL.</p>
<p>Got it? I didn’t even get it on first reading… and I wrote it. The best way to understand what is going on is to run this code yourself and look at what each part is doing.</p>
<p>So now we have our list of URLs for each month. What next?</p>
<p>Well if we go onto the page of a particular month, let’s say March, we will see that the page has multiple paginated tabs at the bottom. Let’s see what happens to the URL when we click on one of these:</p>
<p>We see that if our starting point URL for March, as above, was:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/</code></pre>
<p>When we click through to page 2 it becomes:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130163651/http://www.tahrirdocuments.org/2011/03/page/2/</code></pre>
<p>And for page 3 it becomes:</p>
<pre><code>https://wayback.archive-it.org/2358/20120130163651/http://www.tahrirdocuments.org/2011/03/page/3/</code></pre>
<p>We can see pretty clearly that as we navigate through each page, there appears appended to the URL the string “page/2/” and “page/3/”. So this shouldn’t be too tricky to add to our list of URLs. But we want to avoid having to manually click through the archive for each month to figure out how many pagination tabs are at the bottom of each page.</p>
<p>Fortunately, we don’t have to. Using the “Selector Gadget” tool again we can automate this process by grabbing the highest number that appears in the pagination bar for each month’s pages. The code below achieves this:</p>
<div class="sourceCode" id="cb430"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">urlpages_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span> <span class="co">#create empty character string to deposit our final set of urls</span></span>
<span><span class="va">urlpages</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span> <span class="co">#create empty character string to deposit our urls for each page of each month</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">urls</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span> <span class="co">#for loop for each url stored above</span></span>
<span>  <span class="va">url</span> <span class="op">&lt;-</span> <span class="va">urls</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="co">#take the first url from the vector of urls created above</span></span>
<span>  <span class="va">html</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://xml2.r-lib.org/reference/read_xml.html">read_html</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span> <span class="co">#read the html</span></span>
<span>  <span class="va">pages</span> <span class="op">&lt;-</span> <span class="va">html</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="st">".page"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co">#grab the page element</span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span><span class="op">)</span> <span class="co">#convert to text</span></span>
<span>  <span class="va">pageints</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="va">pages</span><span class="op">)</span> <span class="co">#convert to set of integers</span></span>
<span>  <span class="va">npages</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">pageints</span>, na.rm <span class="op">=</span> <span class="cn">T</span><span class="op">)</span> <span class="co">#get number of highest integer</span></span>
<span>  </span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">j</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">npages</span><span class="op">)</span> <span class="op">{</span> <span class="co">#for loop for each of 1:highest page integer for that month's url</span></span>
<span>  <span class="va">newurl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="va">url</span>,<span class="st">"page/"</span>,<span class="va">j</span>,<span class="st">"/"</span><span class="op">)</span> <span class="co">#create new url by pasting "page/" and then the number of that page, and then "/", matching the url structure identified above</span></span>
<span>  <span class="va">urlpages</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">urlpages</span>, <span class="va">newurl</span><span class="op">)</span> <span class="co">#bind with previously created page urls for each month</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">urlpages_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">urlpages_all</span>, <span class="va">urlpages</span><span class="op">)</span> <span class="co">#bind the monthly page by page urls together</span></span>
<span>  <span class="va">urlpages</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span> <span class="co">#empty urlpages for next iteration of the first for loop</span></span>
<span>  <span class="va">urlpages_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/grep.html">gsub</a></span><span class="op">(</span><span class="st">"page/1/"</span>, <span class="st">""</span>, <span class="va">urlpages_all</span><span class="op">)</span> <span class="co">#get rid of page/1/ as not needed</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>What’s going on here? Well, in the first two lines, we are simply creating an empty character string that we’re going to populate in the subsequent loop. Remember that we have a set of eleven starting URLs for each of months archived on this webpage.</p>
<p>So in the code beginning <code>for (i in seq_along(files)</code> we saying, similar to above, for the beginning url to the end url, do the following in a loop: first, read in the url with <code>url &lt;- urls[i]</code> then read the html it contains with <code>html &lt;- read_html(url)</code>.</p>
<p>After this line, we are getting the pages as a character vector of page numbers by calling the <code><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements()</a></code> function on the “.page” tag. this gives a series of pages stored as e.g. “1” “2” “3”.</p>
<p>In order to be able to see how many there are, we need to extract the highest number that appears in this string. To do this, we first need to reformat it as an “integer” object rather than a “character” object so that R can recognize that these are numbers. So we call <code>pageints &lt;- as.integer(pages)</code>. Then we get the maximum by simply calling: <code>npages &lt;- max(pageints, na.rm = T)</code>.</p>
<p>In the next part of the loop, we are taking the new information we have stored as “npages,” i.e., the number of pagination tabs for each month, and telling R: for each of these pages, define a new url by adding “page/” then the number of the pagination tab “j”, and then “/”. After we’ve bound all of these together, we get a list of URLs that look like this:</p>
<div class="sourceCode" id="cb431"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">urlpages_all</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/"       
## [2] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/page/2/"
## [3] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/page/3/"
## [4] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/page/4/"
## [5] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/page/5/"
## [6] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/page/6/"</code></pre>
<p>So what next?</p>
<p>The next step is to get the URLs for each of the documents contained in the archive for each month. How do we do this? Well, we can once again use the “Selector Gadget” tool to work this out. For the main landing pages of each month, we see listed, as below, each document in a list. For each of these documents, we see that the title, which links to the revolutionary leaflet in question, has two CSS selectors: “h2” and “.post”.</p>
<div class="inline-figure"><img src="data/sampling/gifcap6.gif" style="width:100.0%"></div>
<p>We can again pass these tags through <code><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements()</a></code> to grab what’s contained inside. We can then grab what’s contained inside these by extracting the “children” of these classes. In essence, this just means a lower level tag: tags can have tags within tags and these flow downwards like a family tree (hence the name, I suppose).</p>
<p>So one of the “children” of this HTML tag is the link contained inside, which we can get with calling <code><a href="https://rvest.tidyverse.org/reference/html_children.html">html_children()</a></code> followed by specifying that we want the specific attribute of the web link it encloses with <code>html_attr("href")</code>. The subsequent lines then just remove extraneous information.</p>
<p>The complete loop, then, to retrieve the URL of the page for every leaflet contained on this website is:</p>
<div class="sourceCode" id="cb433"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#GET URLS FOR EACH PAMPHLET</span></span>
<span></span>
<span><span class="va">pamlinks_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">character</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">urlpages_all</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">url</span> <span class="op">&lt;-</span> <span class="va">urlpages_all</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">html</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://xml2.r-lib.org/reference/read_xml.html">read_html</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span></span>
<span>  <span class="va">links</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">".post , h2"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_children.html">html_children</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_attr.html">html_attr</a></span><span class="op">(</span><span class="st">"href"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">`attributes&lt;-`</span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span></span>
<span>  <span class="va">pamlinks_all</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">pamlinks_all</span>, <span class="va">links</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Which gives us:</p>
<div class="sourceCode" id="cb434"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">pamlinks_all</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-3-page-2/"                       
## [2] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/the-most-important-workers-protests/"                    
## [3] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/yes-its-the-workers-and-employees-right-to-strike/"      
## [4] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/the-revolution-is-still-ongoing-2/"                      
## [5] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/voice-of-the-revolution-the-revolution-is-still-ongoing/"
## [6] "https://wayback.archive-it.org/2358/20120130143023/http://www.tahrirdocuments.org/2011/03/we-are-still-continuing-until-victory/"</code></pre>
<div class="sourceCode" id="cb436"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">pamlinks_all</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 523</code></pre>
<p>We see now that we have collected all 523 separate URLs for every revolutionary leaflet contained on these pages. Now we’re in a great position to be able to crawl each page and collect the information we need. This final loop is all we need to go through each URL we’re interested in and collect relevant information on document text, title, date, tags, and the URL to the image of the revolutionary literature itself.</p>
<p>See if you can work out yourselves how each part of this is fitting together. NOTE: if you want to run the final loop on your own machines it will take several hours to complete.</p>
<div class="sourceCode" id="cb438"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df_empty</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq_along</a></span><span class="op">(</span><span class="va">pamlinks_all</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">url</span> <span class="op">&lt;-</span> <span class="va">pamlinks_all</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">html</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://xml2.r-lib.org/reference/read_xml.html">read_html</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Collecting url number "</span>,<span class="va">i</span>,<span class="st">": "</span>, <span class="va">url</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">error</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/conditions.html">tryCatch</a></span><span class="op">(</span><span class="va">html</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://xml2.r-lib.org/reference/read_xml.html">read_html</a></span><span class="op">(</span><span class="va">url</span><span class="op">)</span>,</span>
<span>                    error<span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">e</span><span class="op">)</span> <span class="va">e</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/class.html">inherits</a></span><span class="op">(</span><span class="va">error</span>, <span class="st">'error'</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>title <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>                     date <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>                     text <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>                     imageurl <span class="op">=</span> <span class="cn">NA</span>,</span>
<span>                     tags <span class="op">=</span> <span class="cn">NA</span><span class="op">)</span></span>
<span>    <span class="kw">next</span></span>
<span>  <span class="op">}</span></span>
<span>  </span>
<span>  <span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span>ncol<span class="op">=</span><span class="fl">0</span>, nrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="co">#get titles</span></span>
<span>  <span class="va">titles</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">".title"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">title</span> <span class="op">&lt;-</span> <span class="va">titles</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">df</span><span class="op">$</span><span class="va">title</span> <span class="op">&lt;-</span> <span class="va">title</span></span>
<span>  </span>
<span>  <span class="co">#get date</span></span>
<span>  <span class="va">date</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">".calendar"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="va">df</span><span class="op">$</span><span class="va">date</span> <span class="op">&lt;-</span> <span class="va">date</span></span>
<span>  </span>
<span>  <span class="co">#get text</span></span>
<span>  <span class="va">textsep</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">"p"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="va">text</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="va">textsep</span>, collapse <span class="op">=</span> <span class="st">","</span><span class="op">)</span></span>
<span>  <span class="va">df</span><span class="op">$</span><span class="va">text</span> <span class="op">&lt;-</span> <span class="va">text</span></span>
<span>  </span>
<span>  <span class="co">#get tags</span></span>
<span>  <span class="va">pamtags</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">".category"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_text.html">html_text</a></span><span class="op">(</span>trim<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span>  <span class="va">df</span><span class="op">$</span><span class="va">tags</span> <span class="op">&lt;-</span> <span class="va">pamtags</span></span>
<span>  </span>
<span>  <span class="co">#get link to original pamphlet image</span></span>
<span>  <span class="va">elements_other</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_element.html">html_elements</a></span><span class="op">(</span><span class="va">html</span>, <span class="st">"a"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://rvest.tidyverse.org/reference/html_children.html">html_children</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">url_element</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="va">elements_other</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">imgurl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://stringr.tidyverse.org/reference/str_extract.html">str_extract</a></span><span class="op">(</span><span class="va">url_element</span>, <span class="st">"src=\\S+"</span><span class="op">)</span></span>
<span>  <span class="va">imgurl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/substr.html">substr</a></span><span class="op">(</span><span class="va">imgurl</span>, <span class="fl">6</span>, <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nchar.html">nchar</a></span><span class="op">(</span><span class="va">imgurl</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">df</span><span class="op">$</span><span class="va">imageurl</span> <span class="op">&lt;-</span> <span class="va">imgurl</span></span>
<span>  </span>
<span>  <span class="va">df_empty</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">df_empty</span>, <span class="va">df</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>And now… we’re pretty much there…back where we started!</p>
</div>
<div id="speech-to-text" class="section level2" number="23.5">
<h2>
<span class="header-section-number">23.5</span> Speech to text<a class="anchor" aria-label="anchor" href="#speech-to-text"><i class="fas fa-link"></i></a>
</h2>
<p>There are some R packages that allow the user to connect to the Google Speech-to-Text engine (billing information required to access). You can find such a package <a href="https://github.com/ropensci/googleLanguageR">here</a> but it doesn’t seem to be readily maintained. There is a far wider range of options if you are open to using Python: see, e.g.: <a href="https://realpython.com/python-speech-recognition/">here</a>.</p>
<p>Here, we’re instead going to do the next best thing: capture text that has already been converted from speech. Here, we’re going to be collecting the automated English captioning from YouTube videos. For this, we will use the R package <code>youtubecaption</code>. Because this package connects to an already existing Python package under the hood, you’ll need to have a Conda environment installed. You can download Anaconda Individual Edition <a href="https://www.anaconda.com/products/individual">here</a>.</p>
<p>And to grab the text from a video is as simple as below.</p>
<div class="sourceCode" id="cb439"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/jooyoungseo/youtubecaption">youtubecaption</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">url</span> <span class="op">&lt;-</span> <span class="st">"https://www.youtube.com/watch?v=cpbtcsGE0OA"</span></span>
<span><span class="va">caption</span> <span class="op">&lt;-</span> <span class="fu">get_caption</span><span class="op">(</span><span class="va">url</span><span class="op">)</span></span>
<span><span class="va">caption</span></span></code></pre></div>
<p>And if you wanted to the same thing in Python you would do the following.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb440-1"><a href="exercise-7-sampling-text-information.html#cb440-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install youtube_transcript_api</span>
<span id="cb440-2"><a href="exercise-7-sampling-text-information.html#cb440-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb440-3"><a href="exercise-7-sampling-text-information.html#cb440-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> youtube_transcript_api <span class="im">import</span> YouTubeTranscriptApi</span>
<span id="cb440-4"><a href="exercise-7-sampling-text-information.html#cb440-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb440-5"><a href="exercise-7-sampling-text-information.html#cb440-5" aria-hidden="true" tabindex="-1"></a>YouTubeTranscriptApi.get_transcript(<span class="st">"cpbtcsGE0OA"</span>)</span></code></pre></div>
</div>
<div id="ocr" class="section level2" number="23.6">
<h2>
<span class="header-section-number">23.6</span> OCR<a class="anchor" aria-label="anchor" href="#ocr"><i class="fas fa-link"></i></a>
</h2>
<p>The last major technique that might be of interest for extracting text is Optical Character Recognition (OCR). This is a technique that reads in image files (e.g., .jpg or .png or .pdf) automatically extracts the text contained therein.</p>
<p>A very good package in R for extracting text from images is <code>daiR</code>, details of which can be found <a href="https://cran.r-project.org/web/packages/daiR/index.html">here</a>. This connects again to the Google Cloud Engine (and thus requires billing info.) but it won’t charge you until you’ve spent your first free $300 of credit. This will take a while to spend so you have a good deal amount of tokens before you start incurring expenses.</p>
<p>You can consult <a href="https://dair.info/articles/setting_up_google_storage.html">here</a> for info. on setting up your Google Cloud service account.<br></p>
<p>Once you have done this you’ll be ready to connect to the Google Cloud Engine.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="exercise-6-unsupervised-learning-word-embedding.html"><span class="header-section-number">22</span> Exercise 6: Unsupervised learning (word embedding)</a></div>
<div class="next"><a href="exercise-9-validation.html"><span class="header-section-number">24</span> Exercise 9: Validation</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#exercise-7-sampling-text-information"><span class="header-section-number">23</span> Exercise 7: Sampling text information</a></li>
<li><a class="nav-link" href="#introduction-6"><span class="header-section-number">23.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#online-corpora"><span class="header-section-number">23.2</span> Online corpora</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#replication-datasets"><span class="header-section-number">23.2.1</span> Replication datasets</a></li>
<li><a class="nav-link" href="#curated-corpora"><span class="header-section-number">23.2.2</span> Curated corpora</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#using-apis"><span class="header-section-number">23.3</span> Using APIs</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#other-apis-r-packages"><span class="header-section-number">23.3.1</span> Other APIs (R packages)</a></li></ul>
</li>
<li><a class="nav-link" href="#scraping"><span class="header-section-number">23.4</span> Scraping</a></li>
<li><a class="nav-link" href="#speech-to-text"><span class="header-section-number">23.5</span> Speech to text</a></li>
<li><a class="nav-link" href="#ocr"><span class="header-section-number">23.6</span> OCR</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/cjbarrie/CTA-ED/blob/master/17-sampling-text.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/cjbarrie/CTA-ED/edit/master/17-sampling-text.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Computational Text Analysis</strong>" was written by Christopher Barrie. It was last built on 2022-12-23.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
